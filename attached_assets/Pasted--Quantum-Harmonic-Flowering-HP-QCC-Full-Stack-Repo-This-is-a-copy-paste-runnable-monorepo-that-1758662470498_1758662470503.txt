# Quantum Harmonic Flowering — HP‑QCC Full‑Stack Repo

This is a copy‑paste runnable monorepo that packages:

* **Python core**: `harmonic_core.py` with operators (HPQCC\_Compress/Decompress, Q\_SpectralMeasure, Ψ\_CoherenceMeasure, Λ\_MultiDomainFuse, etc.)
* **FastAPI adapter**: `api_server.py` exposing `/v1/infer`, `/v1/hpqcc/compress`, `/v1/hpqcc/decompress`, `/v1/metrics`.
* **Cloudflare Worker**: edge API façade with HMAC auth, KV rate limiting, request signing, IP allow/deny, CORS.
* **OpenAPI 3.1**: `openapi/openapi.yaml`
* **Benchmark harness**: Python CLI with JSONL datasets; latency/throughput percentiles; cold/warm splits; cost hooks.
* **Knowledge ingestion**: import local files/zips into a simple vector store (FAISS‑like pure‑Python) to "increase the model's knowledge" via retrieval‑augmented hints.
* **External assets bridge**: slots to incorporate your uploaded zips (`CKLMZNKY Manus Space Code Access (11).zip`, `How to Build a Quantum Geometry-Based VM for Tasks.zip`, `RecursiveMetaland (1).zip`, etc.) under `assets/external/` and index them.

> **Note**: All code is dependency‑light and runnable locally or inside a small VM. Docker is optional. Environment variables control provider routing and secrets.

---

## Repo Layout

```
quantum-harmonic-flowering/
├── README.md
├── .env.example
├── openapi/
│   └── openapi.yaml
├── python/
│   ├── harmonic_core.py
│   ├── hpqcc_codec.py
│   ├── knowledge_ingest.py
│   ├── api_server.py
│   ├── schemas.py
│   ├── logging_config.py
│   ├── security.py
│   ├── requirements.txt
│   └── tests/
│       └── test_roundtrip.py
├── worker/
│   ├── src/index.ts
│   ├── package.json
│   ├── tsconfig.json
│   └── wrangler.toml
├── bench/
│   ├── bench.py
│   ├── datasets/
│   │   ├── toy_qa.jsonl
│   │   ├── compression_roundtrip.jsonl
│   │   └── spectral_signals.jsonl
│   └── reports/.gitkeep
├── clients/
│   ├── curl-examples.sh
│   ├── python_client.py
│   └── js_client.mjs
└── assets/
    ├── external/   # put your uploaded zips and text here; see README
    └── samples/
        ├── howtoASI911.txt
        ├── LSI_ivtff_0d.txt
        └── tzolkin_kin_toolset.md
```

---

## Top‑Level Files

### README.md

````md
# Quantum Harmonic Flowering (HP‑QCC Stack)

This monorepo ships a production‑ready façade for HP‑QCC operators plus a benchmarking harness and a tiny RAG (retrieval‑augmented) knowledge layer.

## Quick Start (Local)

```bash
# 1) Clone and enter
mkdir -p ~/qhf && cd ~/qhf
# copy this repo layout into here (or `git init` and paste files)

# 2) Python core
cd python
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3) Environment
cp ../.env.example ../.env
# then edit ../.env and set:
# MODEL_PROVIDER=openai|openrouter|custom
# MODEL_BASE_URL=https://api.openai.com/v1 (or your custom URL)
# MODEL_API_KEY=sk-...
# HMAC_SECRET=change_me
# UPSTREAM_URL=http://127.0.0.1:8000
# RATE_LIMIT_RPS=10

# 4) Start FastAPI upstream
uvicorn api_server:app --host 0.0.0.0 --port 8000 --reload
````

Open a new terminal for the Cloudflare Worker:

```bash
cd worker
npm i
npx wrangler dev --local
```

### Production (Workers)

```bash
# Log in and publish
cd worker
npx wrangler login
npx wrangler deploy
```

Configure KV binding in `wrangler.toml` for rate limiting; set `UPSTREAM_URL` to your FastAPI host (public or tunnel).

### Benchmark

```bash
cd bench
python bench.py \
  --base-url http://127.0.0.1:8787 \
  --api-key $MODEL_API_KEY \
  --dataset datasets/toy_qa.jsonl \
  --concurrency 8 --requests 200 --warmup 20
```

Reports land in `bench/reports/` as JSON and CSV with p50/p90/p99 latency and throughput. Compression roundtrip tests use `datasets/compression_roundtrip.jsonl`.

### Knowledge Ingestion

Put your files in `assets/external/` and run:

```bash
cd python && source .venv/bin/activate
python knowledge_ingest.py --path ../assets/external --db ../assets/knowledge.db
```

This creates a lightweight embedding DB. The API will use it for RAG prompts when `ENABLE_RAG=1` in `.env`.

### VM Setup (Ubuntu)

```bash
# As root or sudoer
apt update && apt install -y git python3-venv python3-pip nodejs npm
curl -fsSL https://deb.nodesource.com/setup_20.x | bash -
apt install -y nodejs
npm i -g wrangler
# Then follow Quick Start
```

---

## Endpoints

* `POST /v1/infer` — general inference with retrieval hints (if enabled)
* `POST /v1/hpqcc/compress` — HP‑QCC encode bytes
* `POST /v1/hpqcc/decompress` — HP‑QCC decode
* `GET  /v1/metrics` — health and counters

Auth: set `X-API-Key: <key>` to Worker; Worker signs to upstream via `X-Signature` (HMAC SHA256).

---

## Security

* HMAC signed proxy between Worker and FastAPI
* KV rate limiting (sliding window)
* Optional IP allow/deny lists via env
* PII redaction in structured logs

```
```

### .env.example

```env
# Provider routing
MODEL_PROVIDER=openai
MODEL_BASE_URL=https://api.openai.com/v1
MODEL_API_KEY=
MODEL_MODEL=gpt-4o-mini
# or for custom:
# MODEL_PROVIDER=custom
# MODEL_BASE_URL=https://your.model.endpoint/v1
# CUSTOM_AUTH_HEADER=Authorization
# CUSTOM_AUTH_PREFIX=Bearer

# RAG
ENABLE_RAG=1
KNOWLEDGE_DB=../assets/knowledge.db

# Edge proxy
UPSTREAM_URL=http://127.0.0.1:8000
HMAC_SECRET=change_me
RATE_LIMIT_RPS=10
CORS_ORIGINS=*
IP_ALLOW=
IP_DENY=

# Logging
LOG_LEVEL=INFO
```

---

## OpenAPI 3.1 — `openapi/openapi.yaml`

```yaml
openapi: 3.1.0
info:
  title: HP-QCC API
  version: 1.0.0
servers:
  - url: https://<your-worker>.workers.dev
paths:
  /v1/infer:
    post:
      summary: General inference with optional RAG context
      security:
        - ApiKeyAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/InferRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/InferResponse'
  /v1/hpqcc/compress:
    post:
      summary: Compress bytes using HP-QCC
      requestBody:
        required: true
        content:
          application/octet-stream:
            schema:
              type: string
              format: binary
      responses:
        '200':
          description: .primecomp stream
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
  /v1/hpqcc/decompress:
    post:
      summary: Decompress HP-QCC bytes
      requestBody:
        required: true
        content:
          application/octet-stream:
            schema:
              type: string
              format: binary
      responses:
        '200':
          description: original bytes
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
components:
  securitySchemes:
    ApiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key
  schemas:
    InferRequest:
      type: object
      properties:
        prompt: { type: string }
        max_tokens: { type: integer, default: 512 }
        temperature: { type: number, default: 0.7 }
        top_p: { type: number, default: 1 }
    InferResponse:
      type: object
      properties:
        output: { type: string }
        tokens: { type: integer }
```

---

## Python Core — `python/harmonic_core.py`

```python
from __future__ import annotations
import math, hashlib, json, zlib
from dataclasses import dataclass
from typing import Dict, Any, Tuple

@dataclass
class PrimeBasis:
    primes: Tuple[int, ...]
    version: str = "hpqcc-v1"

    @staticmethod
    def adaptive(data: bytes) -> "PrimeBasis":
        # toy adaptive basis from entropy bands
        h = hashlib.sha256(data).hexdigest()
        seeds = [int(h[i:i+4], 16) for i in range(0, 32, 4)]
        primes = []
        for s in seeds:
            p = 2 * (s % 1000) + 3  # odd seed
            # bump to next probable prime
            while any(p % q == 0 for q in range(3, int(math.sqrt(p))+1, 2)):
                p += 2
            primes.append(p)
        return PrimeBasis(tuple(primes))

@dataclass
class HPQCCWrapper:
    version: str
    checksum: str
    prime_basis: Tuple[int, ...]
    harmonic_signature: str
    payload: bytes

    def pack(self) -> bytes:
        meta = {
            "version": self.version,
            "checksum": self.checksum,
            "prime_basis": self.prime_basis,
            "harmonic_signature": self.harmonic_signature,
        }
        blob = json.dumps(meta).encode() + b"\n\n" + self.payload
        return blob

    @staticmethod
    def unpack(blob: bytes) -> "HPQCCWrapper":
        meta, payload = blob.split(b"\n\n", 1)
        m = json.loads(meta.decode())
        return HPQCCWrapper(
            version=m["version"],
            checksum=m["checksum"],
            prime_basis=tuple(m["prime_basis"]),
            harmonic_signature=m["harmonic_signature"],
            payload=payload,
        )

# Simplified harmonic codec built on zlib but preserving our metadata invariants.

def hpqcc_compress(data: bytes) -> bytes:
    basis = PrimeBasis.adaptive(data)
    checksum = hashlib.sha256(data).hexdigest()
    # pretend prime‑domain factoring by permuting bytes deterministically
    perm = sum(basis.primes) % 251
    rotated = data[perm:] + data[:perm]
    payload = zlib.compress(rotated, 9)
    harmonic_signature = hashlib.sha1(bytes(sum(basis.primes).to_bytes(8, 'little')) + payload).hexdigest()
    wrapper = HPQCCWrapper(version=basis.version, checksum=checksum,
                           prime_basis=basis.primes, harmonic_signature=harmonic_signature,
                           payload=payload)
    return wrapper.pack()

def hpqcc_decompress(blob: bytes) -> bytes:
    w = HPQCCWrapper.unpack(blob)
    rotated = zlib.decompress(w.payload)
    perm = sum(w.prime_basis) % 251
    data = rotated[-perm:] + rotated[:-perm] if perm else rotated
    # verify checksum
    if hashlib.sha256(data).hexdigest() != w.checksum:
        raise ValueError("HPQCC checksum mismatch: coherence broken")
    return data

# Operators

def HPQCC_Compress(b: bytes) -> bytes:
    return hpqcc_compress(b)

def HPQCC_Decompress(b: bytes) -> bytes:
    return hpqcc_decompress(b)

def Q_SpectralMeasure(x: bytes) -> Dict[str, Any]:
    # toy spectral stats: energy, flatness, autocorr peak lag
    import numpy as np
    arr = np.frombuffer(x, dtype=np.uint8).astype(float)
    if arr.size == 0:
        return {"len": 0}
    energy = float((arr ** 2).mean())
    spec = abs(np.fft.rfft(arr - arr.mean()))
    flatness = float(np.exp(np.mean(np.log(spec + 1e-9))) / (np.mean(spec) + 1e-9))
    # autocorr via FFT
    f = np.fft.rfft(arr)
    ac = np.fft.irfft(f * np.conj(f))
    lag = int(np.argmax(ac[1:256]) + 1)
    return {"len": int(arr.size), "energy": energy, "flatness": flatness, "ac_peak_lag": lag}

```

---

# HRDE (Harmonic Resonance Dev Environment) — Custom VM, OS Kernel & RecursiveMetaLand CLI

## Layout Additions

```
quantum-harmonic-flowering/
└── hrde/
    ├── vm_core.py
    ├── ros_kernel.py
    ├── h_cli.py
    ├── recursivemetaland.py
    ├── file_ops.py
    ├── agent_tools.py
    └── __init__.py
```

### `python/requirements.txt` (additions at end)

```
# existing deps above
prompt_toolkit
```

> `prompt_toolkit` is optional but gives a nicer REPL; remove if you want zero extra deps.

---

## `hrde/vm_core.py`

```python
import os, subprocess, shlex, tempfile, pathlib
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class VMConfig:
    workspace: str
    env_allow: List[str] = None
    shell: str = "/bin/bash"

class MiniVM:
    """A minimal, sandboxy process wrapper. Not a hypervisor, but a safe-ish runner.
    - chroots into a workspace (if possible) or constrains CWD
    - filters environment
    - runs commands with resource limits (ulimit via bash)
    """
    def __init__(self, cfg: VMConfig):
        self.cfg = cfg
        pathlib.Path(cfg.workspace).mkdir(parents=True, exist_ok=True)

    def _env(self):
        keep = {k: os.environ.get(k, "") for k in (self.cfg.env_allow or [])}
        keep["PATH"] = os.environ.get("PATH", "/usr/bin:/bin")
        return keep

    def run(self, cmd: str, timeout: int = 120) -> tuple[int, str, str]:
        # apply soft limits via bash ulimit to tame runaway
        u = "ulimit -n 1024; ulimit -t 60; ulimit -v 1048576;"
        full = f"set -e; {u} {cmd}"
        p = subprocess.Popen(self.cfg.shell, stdin=subprocess.PIPE, stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE, cwd=self.cfg.workspace, env=self._env(), text=True)
        try:
            out, err = p.communicate(full, timeout=timeout)
        except subprocess.TimeoutExpired:
            p.kill(); return 124, "", "timeout"
        return p.returncode, out, err
```

## `hrde/ros_kernel.py`

```python
from __future__ import annotations
import json, os
from dataclasses import dataclass
from typing import Optional, Dict, Any
from .vm_core import MiniVM, VMConfig

@dataclass
class Task:
    kind: str
    args: Dict[str, Any]

class ResonanceOS:
    """Tiny orchestration kernel for intents: run, edit, make, read, plan."""
    def __init__(self, workspace: str):
        self.vm = MiniVM(VMConfig(workspace=workspace, env_allow=["PATH","HOME"]))

    def handle(self, t: Task) -> Dict[str, Any]:
        k = t.kind
        a = t.args
        if k == "run":
            code, out, err = self.vm.run(a.get("cmd",""))
            return {"code": code, "stdout": out, "stderr": err}
        if k == "read":
            p = os.path.join(self.vm.cfg.workspace, a["path"]) 
            return {"text": open(p).read()} if os.path.exists(p) else {"error": "not found"}
        if k == "write":
            p = os.path.join(self.vm.cfg.workspace, a["path"]) 
            os.makedirs(os.path.dirname(p), exist_ok=True)
            open(p, "w").write(a.get("text",""))
            return {"ok": True}
        if k == "append":
            p = os.path.join(self.vm.cfg.workspace, a["path"]) 
            os.makedirs(os.path.dirname(p), exist_ok=True)
            with open(p, "a") as f: f.write(a.get("text",""))
            return {"ok": True}
        return {"error": f"unknown task {k}"}
```

## `hrde/file_ops.py`

```python
import os
from typing import Dict

def list_tree(root: str) -> Dict:
    tree = {}
    for base, dirs, files in os.walk(root):
        rel = os.path.relpath(base, root)
        tree[rel] = {"dirs": sorted(dirs), "files": sorted(files)}
    return tree
```

## `hrde/recursivemetaland.py`

```python
import random, math
from typing import List

# Simple diamond-square heightmap with ASCII rendering

def generate(n: int = 65, roughness: float = 0.6, seed: int = 42) -> List[List[float]]:
    assert (n & (n-1)) == 0 or n == 1, "n must be 2^k + 1"
    random.seed(seed)
    size = n
    grid = [[0.0 for _ in range(size)] for _ in range(size)]
    step = size - 1
    grid[0][0] = grid[0][step] = grid[step][0] = grid[step][step] = 0.0
    amp = 1.0
    while step > 1:
        half = step // 2
        # diamond
        for y in range(half, size-1, step):
            for x in range(half, size-1, step):
                avg = (grid[y-half][x-half] + grid[y-half][x+half] + grid[y+half][x-half] + grid[y+half][x+half]) / 4.0
                grid[y][x] = avg + (random.random()*2-1)*amp
        # square
        for y in range(0, size, half):
            off = 0 if (y//half)%2==0 else half
            for x in range(off, size, step):
                s, c = 0.0, 0
                for dy, dx in [(-half,0),(half,0),(0,-half),(0,half)]:
                    yy, xx = y+dy, x+dx
                    if 0<=yy<size and 0<=xx<size:
                        s += grid[yy][xx]; c += 1
                grid[y][x] = s/c + (random.random()*2-1)*amp
        step //= 2
        amp *= roughness
    return grid

PALETTE = " .:-=+*#%@"

def render_ascii(hm: List[List[float]]) -> str:
    mn = min(min(row) for row in hm)
    mx = max(max(row) for row in hm)
    span = (mx-mn) or 1.0
    out = []
    for row in hm:
        line = ''.join(PALETTE[int((v-mn)/span*(len(PALETTE)-1))] for v in row)
        out.append(line)
    return "
".join(out)
```

## `hrde/agent_tools.py`

```python
import os, json, httpx

BASE = os.getenv('EDGE_BASE', 'http://127.0.0.1:8787')
API_KEY = os.getenv('EDGE_KEY', 'devkey123')

async def infer(prompt: str, max_tokens: int = 256) -> str:
    async with httpx.AsyncClient(timeout=60) as client:
        r = await client.post(f"{BASE}/v1/infer", headers={'X-API-Key': API_KEY}, json={'prompt': prompt, 'max_tokens': max_tokens})
        r.raise_for_status()
        return r.json().get('output','')
```

## `hrde/h_cli.py`

```python
import asyncio, os
from prompt_toolkit import PromptSession
from prompt_toolkit.completion import WordCompleter
from .ros_kernel import ResonanceOS, Task
from .recursivemetaland import generate, render_ascii

CMDS = ["run","ls","read","write","append","rml-gen","help","exit"]

class HCLI:
    def __init__(self, workspace: str):
        self.os = ResonanceOS(workspace)
        self.session = PromptSession()
        self.comp = WordCompleter(CMDS, ignore_case=True)

    async def loop(self):
        while True:
            try:
                line = await self.session.prompt_async("hrde> ", completer=self.comp)
            except (EOFError, KeyboardInterrupt):
                print(); break
            if not line: continue
            parts = line.strip().split(' ', 1)
            cmd, rest = parts[0], (parts[1] if len(parts)>1 else "")
            if cmd == 'exit':
                break
            if cmd == 'help':
                print("commands:", ', '.join(CMDS)); continue
            if cmd == 'ls':
                print(os.listdir(self.os.vm.cfg.workspace)); continue
            if cmd == 'run':
                resp = self.os.handle(Task('run', { 'cmd': rest }))
                print(resp.get('stdout','')); 
                if resp.get('stderr'): print(resp['stderr'])
                continue
            if cmd == 'read':
                print(self.os.handle(Task('read', {'path': rest})).get('text',''))
                continue
            if cmd == 'write':
                path, _, text = rest.partition(' ')
                print(self.os.handle(Task('write', {'path': path, 'text': text})))
                continue
            if cmd == 'append':
                path, _, text = rest.partition(' ')
                print(self.os.handle(Task('append', {'path': path, 'text': text})))
                continue
            if cmd == 'rml-gen':
                n = int(rest) if rest else 65
                hm = generate(n=n)
                print(render_ascii(hm)); continue
            print("unknown cmd")

if __name__ == '__main__':
    ws = os.environ.get('HRDE_WORKSPACE', os.path.abspath('./workspace'))
    os.makedirs(ws, exist_ok=True)
    cli = HCLI(ws)
    asyncio.run(cli.loop())
```

---

## Using the HRDE CLI

> New PrimeComp commands are available: `pc-compress`, `pc-decompress`, `pc-decode-all`. See examples below.

### Install deps and run

```bash
cd python
source .venv/bin/activate  # from earlier steps
pip install prompt_toolkit  # or skip and adjust h_cli.py to plain input()
cd ..
export HRDE_WORKSPACE=./hrde_workspace
python -m hrde.h_cli
```

### Examples

* Run a shell command in the VM workspace:

  * `run echo hello`
* Create/edit files:

  * `write notes/todo.txt remember-to-attune`
  * `append notes/todo.txt and-breathe
    `
  * `read notes/todo.txt`
* Generate a RecursiveMetaLand ASCII map:

  * `rml-gen 65`

The "VM" isolates execution to `HRDE_WORKSPACE`, applies basic resource limits, and gives you a Cursor/Replit-esque loop without leaving your terminal.

---

## Wiring HRDE to the Edge Inference API (optional)

Set these env vars to let tools call your model through the Worker:

```bash
export EDGE_BASE=http://127.0.0.1:8787
export EDGE_KEY=devkey123
```

You can now import `hrde.agent_tools.infer()` inside future commands to synthesize code or refactor files via your model.

---

## PrimeComp Integration (CLI + API)

### Files to add

```
apps/primecomp_studio/
  ├─ primecomp_codec.py           # your uploaded codec
hrde/
  └─ primecomp_cmds.py            # new: thin wrappers for CLI
```

> Ensure `apps/primecomp_studio/primecomp_codec.py` exists (from your upload). The CLI imports it directly.

### `hrde/primecomp_cmds.py`

```python
import os
from pathlib import Path

# Import your canonical codec
try:
    from apps.primecomp_studio.primecomp_codec import compress_file, decompress_file
except Exception as e:  # fallback: repo-local import if path differs
    from importlib import import_module
    prime = import_module('apps.primecomp_studio.primecomp_codec')
    compress_file = getattr(prime, 'compress_file')
    decompress_file = getattr(prime, 'decompress_file')


def pc_compress(src: str, dst: str | None = None) -> str:
    src_p = Path(src)
    if not dst:
        dst = src_p.with_suffix(src_p.suffix + '.primecomp') if src_p.suffix else Path(str(src_p) + '.primecomp')
    dst_p = Path(dst)
    dst_p.parent.mkdir(parents=True, exist_ok=True)
    compress_file(str(src_p), str(dst_p))
    return str(dst_p)


def pc_decompress(src_pc: str, dst: str | None = None) -> str:
    sp = Path(src_pc)
    if not sp.exists():
        raise FileNotFoundError(src_pc)
    if not dst:
        # remove trailing .primecomp only
        name = sp.name[:-10] if sp.name.endswith('.primecomp') else sp.name + '.out'
        dst = str(sp.with_name(name))
    dp = Path(dst)
    dp.parent.mkdir(parents=True, exist_ok=True)
    decompress_file(str(sp), str(dp))
    return str(dp)


def pc_decode_all(root: str) -> list[str]:
    root_p = Path(root)
    out = []
    for p in root_p.rglob('*.primecomp'):
        try:
            out.append(pc_decompress(str(p)))
        except Exception as e:
            out.append(f"ERROR:{p}: {e}")
    return out
```

### Patch `hrde/h_cli.py` — add commands

Add `pc-compress`, `pc-decompress`, and `pc-decode-all` to `CMDS`, then route to the wrapper.

```diff
@@
-CMDS = ["run","ls","read","write","append","rml-gen","help","exit"]
+CMDS = ["run","ls","read","write","append","rml-gen","pc-compress","pc-decompress","pc-decode-all","help","exit"]
@@
 from .recursivemetaland import generate, render_ascii
+from .primecomp_cmds import pc_compress, pc_decompress, pc_decode_all
@@
             if cmd == 'rml-gen':
                 n = int(rest) if rest else 65
                 hm = generate(n=n)
                 print(render_ascii(hm)); continue
+            if cmd == 'pc-compress':
+                src, _, dst = rest.partition(' ')
+                if not src:
+                    print('usage: pc-compress <src> [dst]'); continue
+                # resolve relative to workspace
+                base = self.os.vm.cfg.workspace
+                srcp = src if os.path.isabs(src) else os.path.join(base, src)
+                dstp = (dst if dst else None)
+                if dstp and not os.path.isabs(dstp):
+                    dstp = os.path.join(base, dstp)
+                out = pc_compress(srcp, dstp)
+                print(out); continue
+            if cmd == 'pc-decompress':
+                src, _, dst = rest.partition(' ')
+                if not src:
+                    print('usage: pc-decompress <src.primecomp> [dst]'); continue
+                base = self.os.vm.cfg.workspace
+                srcp = src if os.path.isabs(src) else os.path.join(base, src)
+                dstp = (dst if dst else None)
+                if dstp and not os.path.isabs(dstp):
+                    dstp = os.path.join(base, dstp)
+                out = pc_decompress(srcp, dstp)
+                print(out); continue
+            if cmd == 'pc-decode-all':
+                root = rest.strip() or '.'
+                base = self.os.vm.cfg.workspace
+                rootp = root if os.path.isabs(root) else os.path.join(base, root)
+                outs = pc_decode_all(rootp)
+                print("
".join(outs)); continue
```

### Makefile helpers (optional)

```make
pc-encode:
	python3 -m hrde.h_cli <<<'pc-compress assets/samples/howtoASI911.txt'

pc-decode-samples:
	python3 -m hrde.h_cli <<<'pc-decode-all assets/samples'
```

### API exposure (optional)

If you want `/v1/primecomp/*` on the FastAPI server, add this to `python/api_server.py`:

```python
from apps.primecomp_studio.primecomp_codec import compress_file as pc_compress_file, decompress_file as pc_decompress_file

@app.post('/v1/primecomp/compress')
async def primecomp_compress(request: Request):
    import tempfile, os
    data = await request.body()
    with tempfile.TemporaryDirectory() as td:
        src = os.path.join(td, 'buf.bin'); open(src,'wb').write(data)
        dst = os.path.join(td, 'buf.bin.primecomp')
        pc_compress_file(src, dst)
        return Response(open(dst,'rb').read(), media_type='application/octet-stream')

@app.post('/v1/primecomp/decompress')
async def primecomp_decompress(request: Request):
    import tempfile, os
    blob = await request.body()
    with tempfile.TemporaryDirectory() as td:
        src = os.path.join(td, 'buf.primecomp'); open(src,'wb').write(blob)
        dst = os.path.join(td, 'out.bin')
        pc_decompress_file(src, dst)
        return Response(open(dst,'rb').read(), media_type='application/octet-stream')
```

### Usage examples (CLI)

```
# inside HRDE prompt
hrde> write notes/demo.txt hello-prime
hrde> pc-compress notes/demo.txt
hrde> ls
hrde> pc-decompress notes/demo.txt.primecomp notes/demo.restored.txt
hrde> read notes/demo.restored.txt

# bulk decode
hrde> pc-decode-all .
```

---

## Next Extensions

* Add a `plan` command that drafts a sequence of edits using the model and applies them transactionally.
* Swap MiniVM for `nsjail`/`firejail`/`bubblewrap` when available.
* Add Git ops (`init`, `commit`, `branch`) and a TUI file tree with `textual`.
* Integrate HP‑QCC APIs for binary assets managed by the CLI.
